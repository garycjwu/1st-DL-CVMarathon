{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTT 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例 ，完成以下問題：\n",
    "\n",
    "* ① 印出最新文章的「作者」「標題」「時間」\n",
    "* ② 印出第一頁所有文章的「作者」「標題」「時間」\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② 印出第一頁所有文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/nba/index.html'\n",
    "\n",
    "try:\n",
    "    resp = requests.get(url, 'html5lib')\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print('Failed to load website')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "soup = BeautifulSoup(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: LargerThanU, title: [討論] 近十年來影響最大的一個Play, time: 5/21\n",
      "author: ericf129, title: [新聞] 幸運中30萬美元樂透彩 亞瑞納斯感謝遊民, time: 5/21\n",
      "author: ckny, title: [情報] Pierce的歷史5人沒詹皇 Perkins:褻瀆神明, time: 5/21\n",
      "author: ckny, title: [專欄] 魔術:Jordan是GOAT 但LBJ有機會追上他, time: 5/21\n",
      "author: manuginobii, title: [花邊] 加索:Kobe用西語跟我交流 為關係奠定基, time: 5/21\n",
      "author: ckny, title: [花邊] Seth Curry談哥哥:寧願競爭也從未想同隊, time: 5/21\n",
      "author: zx084, title: [問卷] (100P)運動明星代言與電子商務形象對於消費者購買意圖行為研, time: 5/21\n",
      "author: ghost069, title: [新聞] 狀元Zion若不打NBA想當喜劇演員　曝菜鳥, time: 5/21\n",
      "author: Zodelyst, title: Re: [外絮] 20位曾在季後賽被MJ淘汰掉的名人堂球星, time: 5/21\n",
      "author: sad9876520, title: [討論] 喬丹遇到真惡漢時還會嘴砲嗎?, time: 5/21\n",
      "author: james008, title: [新聞] 談詹皇領導風格 Love:嚴格但也很照顧隊友, time: 5/21\n",
      "author: allenblack, title: Re: [討論] 如果俠客在現今NBA，還會很有宰制力嗎?, time: 5/21\n",
      "author: Wojnarowski, title: [花邊] VC選MJ、Kobe、LBJ為歷史前三, time: 5/21\n",
      "author: Vicky, title: [新聞] 已無法團結當年陣容 公牛老闆揭露王朝殞, time: 5/21\n",
      "author: YC1018, title: [專欄] NBA 2020 選秀勘查 | 球三 LaMelo Ball, time: 5/21\n",
      "author: thnlkj0665, title: [花邊] 喬丹公牛生涯對位983人  僅一人得分超越他, time: 5/21\n",
      "author: Kazmier, title: [情報] Hollinger:我與主流輿論在本屆選秀看法, time: 5/21\n",
      "author: Ivers, title: [情報] 1994TODAY, time: 5/21\n",
      "author: Daniels, title: [新聞] 不拆能7冠？喬丹被老闆打臉, time: 5/21\n",
      "author: Vedan, title: [公告] 板規v6.8, time: 5/24\n",
      "author: qazwsx879345, title: [公告] 版主上任相關事項, time: 10/25\n",
      "author: Acetoxy, title: [情報] SEASON Schedule 賽程 March 19–20, time: 3/02\n",
      "author: Vedan, title: [公告] 第一次被退文，可在三天後刪除退文, time: 3/09\n",
      "author: Vedan, title: [公告] 板務說明 (發錢), time: 4/03\n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', 'r-ent')\n",
    "\n",
    "for div in divs:\n",
    "    author = div.find('div', 'author').text.strip()\n",
    "    #title = div.find(class_='title')\n",
    "    title = div.find('div', 'title').text.strip()\n",
    "    time = div.find('div', 'date').text.strip()\n",
    "    print(f'author: {author}, title: {title}, time: {time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 印出最新文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Daniels', 'title': '[新聞] 不拆能7冠？喬丹被老闆打臉', 'time': 'Thu May 21 22:08:36 2020'}\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "ptt = 'https://www.ptt.cc/'\n",
    "\n",
    "divs = soup.find_all('div', 'r-ent')\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        data = dict()\n",
    "        data['author'] = div.find('div', 'author').text.strip()\n",
    "        #title = div.find(class_='title')\n",
    "        data['title'] = div.find('div', 'title').text.strip()\n",
    "        \n",
    "        href = div.find('a')['href']\n",
    "        resp2 = requests.get(ptt+href, 'html5lib')\n",
    "        soup2 = BeautifulSoup(resp2.text)\n",
    "        time = soup2.find_all('span', 'article-meta-value')[-1].text.strip()\n",
    "        data['time'] = time\n",
    "        \n",
    "        posts.append(data)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key = lambda x : x['time'])\n",
    "print(posts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ 試著爬爬看其他版的文章(mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'WillWaiting', 'title': '[閒聊] MLB的滑球革命', 'time': 'Wed May 20 20:20:23 2020'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/mlb/index.html'\n",
    "\n",
    "try:\n",
    "    resp = requests.get(url, 'html5lib')\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print('Failed to load website')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "soup = BeautifulSoup(resp.text)\n",
    "posts = []\n",
    "ptt = 'https://www.ptt.cc/'\n",
    "divs = soup.find_all('div', 'r-ent')\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        data = dict()\n",
    "        data['author'] = div.find('div', 'author').text.strip()\n",
    "        #title = div.find(class_='title')\n",
    "        data['title'] = div.find('div', 'title').text.strip()\n",
    "        \n",
    "        href = div.find('a')['href']\n",
    "        resp2 = requests.get(ptt+href, 'html5lib')\n",
    "        soup2 = BeautifulSoup(resp2.text)\n",
    "        time = soup2.find_all('span', 'article-meta-value')[-1].text.strip()\n",
    "        data['time'] = time\n",
    "        \n",
    "        posts.append(data)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key = lambda x : x['time'])\n",
    "print(posts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ 試著爬爬看其他版的文章(gossiping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'HiroXu', 'title': '[協尋] 5/11 20:00五權五街車禍行車記錄器', 'time': 'Tue May 12 03:32:16 2020'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/gossiping/index.html'\n",
    "\n",
    "try:\n",
    "    resp = requests.get(url, 'html5lib', cookies={'over18': '1'})\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print('Failed to load website')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "soup = BeautifulSoup(resp.text)\n",
    "posts = []\n",
    "ptt = 'https://www.ptt.cc/'\n",
    "divs = soup.find_all('div', 'r-ent')\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        data = dict()\n",
    "        data['author'] = div.find('div', 'author').text.strip()\n",
    "        #title = div.find(class_='title')\n",
    "        data['title'] = div.find('div', 'title').text.strip()\n",
    "        \n",
    "        href = div.find('a')['href']\n",
    "        resp2 = requests.get(ptt+href, 'html5lib', cookies={'over18': '1'})\n",
    "        soup2 = BeautifulSoup(resp2.text)\n",
    "        time = soup2.find_all('span', 'article-meta-value')[-1].text.strip()\n",
    "        data['time'] = time\n",
    "        \n",
    "        posts.append(data)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key = lambda x : x['time'])\n",
    "print(posts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
