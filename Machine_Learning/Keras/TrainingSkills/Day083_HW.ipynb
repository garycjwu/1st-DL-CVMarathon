{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較有 BN 在 Batch_size = 2, 16, 32, 128, 256 下的差異\n",
    "2. 請嘗試將 BN 放在 Activation 之前，並比較訓練結果\n",
    "3. 請於 BN 放在 Input Layer 後，並比較結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Activation\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, normBeforeAct=True, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            \n",
    "            if normBeforeAct:  \n",
    "                x = BatchNormalization()(x)\n",
    "                x = Activation(\"relu\")(x)\n",
    "            else:\n",
    "                x = Activation(\"relu\")(x)\n",
    "                x = BatchNormalization()(x)\n",
    "        else:\n",
    "            \n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                       activation=\"relu\", \n",
    "                                       name=\"hidden_layer\"+str(i+1))(x)\n",
    "            if normBeforeAct:\n",
    "                x = BatchNormalization()(x)\n",
    "                x = Activation(\"relu\")(x)\n",
    "            else:\n",
    "                x = Activation(\"relu\")(x)\n",
    "                x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = [32, 128, 256]\n",
    "BEFORE_ACTIVATE = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, use_preact: True, batch_size: 32\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 1.7668 - accuracy: 0.3766 - val_loss: 1.7334 - val_accuracy: 0.3799\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.5429 - accuracy: 0.4552 - val_loss: 1.5783 - val_accuracy: 0.4433\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.4346 - accuracy: 0.4884 - val_loss: 1.5500 - val_accuracy: 0.4418\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.3631 - accuracy: 0.5145 - val_loss: 1.4835 - val_accuracy: 0.4776\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.2900 - accuracy: 0.5421 - val_loss: 1.4899 - val_accuracy: 0.4848\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.2333 - accuracy: 0.5609 - val_loss: 1.4202 - val_accuracy: 0.5019\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.1772 - accuracy: 0.5821 - val_loss: 1.4635 - val_accuracy: 0.4854\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.1259 - accuracy: 0.5988 - val_loss: 1.4830 - val_accuracy: 0.4857\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0823 - accuracy: 0.6130 - val_loss: 1.4259 - val_accuracy: 0.5134\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0311 - accuracy: 0.6330 - val_loss: 1.7083 - val_accuracy: 0.4660\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9925 - accuracy: 0.6454 - val_loss: 1.8077 - val_accuracy: 0.4369\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9446 - accuracy: 0.6644 - val_loss: 1.9175 - val_accuracy: 0.4391\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9067 - accuracy: 0.6777 - val_loss: 1.5843 - val_accuracy: 0.4893\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.8670 - accuracy: 0.6896 - val_loss: 1.5114 - val_accuracy: 0.5199\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.8312 - accuracy: 0.7040 - val_loss: 1.7005 - val_accuracy: 0.4856\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7951 - accuracy: 0.7165 - val_loss: 1.5778 - val_accuracy: 0.5064\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7625 - accuracy: 0.7266 - val_loss: 1.6014 - val_accuracy: 0.5118\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7253 - accuracy: 0.7408 - val_loss: 2.0015 - val_accuracy: 0.4613\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.6975 - accuracy: 0.7518 - val_loss: 2.2313 - val_accuracy: 0.4586\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6692 - accuracy: 0.7608 - val_loss: 1.6697 - val_accuracy: 0.5268\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6519 - accuracy: 0.7664 - val_loss: 1.9247 - val_accuracy: 0.4781\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.6180 - accuracy: 0.7807 - val_loss: 1.8401 - val_accuracy: 0.5092\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.6015 - accuracy: 0.7840 - val_loss: 1.9815 - val_accuracy: 0.4829\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5698 - accuracy: 0.7950 - val_loss: 2.0523 - val_accuracy: 0.4757\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.5572 - accuracy: 0.8021 - val_loss: 2.1228 - val_accuracy: 0.4660\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.5306 - accuracy: 0.8116 - val_loss: 1.8761 - val_accuracy: 0.5095\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.5183 - accuracy: 0.8148 - val_loss: 1.9246 - val_accuracy: 0.4747\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.5039 - accuracy: 0.8192 - val_loss: 2.1000 - val_accuracy: 0.4863\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4832 - accuracy: 0.8274 - val_loss: 1.8740 - val_accuracy: 0.5220\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4708 - accuracy: 0.8331 - val_loss: 2.0553 - val_accuracy: 0.5047\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4595 - accuracy: 0.8349 - val_loss: 1.9360 - val_accuracy: 0.5066\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4455 - accuracy: 0.8404 - val_loss: 2.2486 - val_accuracy: 0.4820\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4329 - accuracy: 0.8442 - val_loss: 2.3160 - val_accuracy: 0.4824\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4218 - accuracy: 0.8484 - val_loss: 2.3145 - val_accuracy: 0.4747\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4104 - accuracy: 0.8542 - val_loss: 2.2038 - val_accuracy: 0.5073\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4013 - accuracy: 0.8559 - val_loss: 2.0901 - val_accuracy: 0.5317\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3836 - accuracy: 0.8626 - val_loss: 2.2252 - val_accuracy: 0.5135\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3858 - accuracy: 0.8623 - val_loss: 2.4355 - val_accuracy: 0.4928\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3691 - accuracy: 0.8688 - val_loss: 2.2328 - val_accuracy: 0.4911\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.3609 - accuracy: 0.8722 - val_loss: 2.2544 - val_accuracy: 0.5041\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.3511 - accuracy: 0.8750 - val_loss: 2.3808 - val_accuracy: 0.5001\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3385 - accuracy: 0.8800 - val_loss: 2.4015 - val_accuracy: 0.4923\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3358 - accuracy: 0.8810 - val_loss: 2.4152 - val_accuracy: 0.4937\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3298 - accuracy: 0.8844 - val_loss: 2.5100 - val_accuracy: 0.4992\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.3086 - accuracy: 0.8904 - val_loss: 2.4543 - val_accuracy: 0.5188\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3115 - accuracy: 0.8894 - val_loss: 2.7382 - val_accuracy: 0.5004\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3115 - accuracy: 0.8903 - val_loss: 2.5010 - val_accuracy: 0.5080\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.3040 - accuracy: 0.8913 - val_loss: 2.2867 - val_accuracy: 0.5265\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2961 - accuracy: 0.8930 - val_loss: 2.4701 - val_accuracy: 0.5120\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.2906 - accuracy: 0.8964 - val_loss: 2.6121 - val_accuracy: 0.4899\n",
      "Numbers of exp: 1, use_preact: True, batch_size: 128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.7272 - accuracy: 0.3961 - val_loss: 2.0079 - val_accuracy: 0.3459\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.4603 - accuracy: 0.4845 - val_loss: 2.1540 - val_accuracy: 0.2971\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.3376 - accuracy: 0.5263 - val_loss: 1.6773 - val_accuracy: 0.4047\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.2445 - accuracy: 0.5573 - val_loss: 1.7274 - val_accuracy: 0.3861\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.1680 - accuracy: 0.5863 - val_loss: 1.7028 - val_accuracy: 0.4058\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 1.0907 - accuracy: 0.6108 - val_loss: 1.6661 - val_accuracy: 0.4251\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.0302 - accuracy: 0.6317 - val_loss: 2.0962 - val_accuracy: 0.3073\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.9672 - accuracy: 0.6550 - val_loss: 1.7210 - val_accuracy: 0.4011\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.8978 - accuracy: 0.6810 - val_loss: 2.0522 - val_accuracy: 0.3608\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.8444 - accuracy: 0.6981 - val_loss: 1.7575 - val_accuracy: 0.4275\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.7751 - accuracy: 0.7238 - val_loss: 1.7642 - val_accuracy: 0.4374\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.7292 - accuracy: 0.7395 - val_loss: 1.9105 - val_accuracy: 0.3924\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6745 - accuracy: 0.7588 - val_loss: 2.0776 - val_accuracy: 0.4212\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.6164 - accuracy: 0.7814 - val_loss: 1.8821 - val_accuracy: 0.4365\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5732 - accuracy: 0.7956 - val_loss: 1.9446 - val_accuracy: 0.4389\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.5319 - accuracy: 0.8109 - val_loss: 1.9465 - val_accuracy: 0.4648\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.4841 - accuracy: 0.8282 - val_loss: 2.0798 - val_accuracy: 0.4511\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.4445 - accuracy: 0.8422 - val_loss: 2.2098 - val_accuracy: 0.4356\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.4195 - accuracy: 0.8549 - val_loss: 2.1396 - val_accuracy: 0.4398\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.3899 - accuracy: 0.8613 - val_loss: 2.3144 - val_accuracy: 0.4562\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.3656 - accuracy: 0.8709 - val_loss: 2.4583 - val_accuracy: 0.4602\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3456 - accuracy: 0.8772 - val_loss: 2.3155 - val_accuracy: 0.4280\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.3214 - accuracy: 0.8868 - val_loss: 2.6350 - val_accuracy: 0.4376\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3095 - accuracy: 0.8906 - val_loss: 2.7798 - val_accuracy: 0.4475\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.2846 - accuracy: 0.9003 - val_loss: 2.3759 - val_accuracy: 0.4749\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.2672 - accuracy: 0.9045 - val_loss: 2.6099 - val_accuracy: 0.4507\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.2511 - accuracy: 0.9115 - val_loss: 2.8350 - val_accuracy: 0.4575\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.2392 - accuracy: 0.9167 - val_loss: 2.7503 - val_accuracy: 0.4679\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.2337 - accuracy: 0.9172 - val_loss: 2.7661 - val_accuracy: 0.4611\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.2248 - accuracy: 0.9219 - val_loss: 3.0361 - val_accuracy: 0.4429\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.2164 - accuracy: 0.9256 - val_loss: 3.0147 - val_accuracy: 0.4592\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.2045 - accuracy: 0.9289 - val_loss: 3.2868 - val_accuracy: 0.4585\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.2030 - accuracy: 0.9293 - val_loss: 3.0391 - val_accuracy: 0.4850\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.1897 - accuracy: 0.9332 - val_loss: 3.1034 - val_accuracy: 0.4708\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.1821 - accuracy: 0.9371 - val_loss: 3.3346 - val_accuracy: 0.4661\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.1716 - accuracy: 0.9411 - val_loss: 3.0643 - val_accuracy: 0.4784\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1769 - accuracy: 0.9387 - val_loss: 3.2425 - val_accuracy: 0.4370\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1644 - accuracy: 0.9422 - val_loss: 3.2090 - val_accuracy: 0.4391\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1648 - accuracy: 0.9434 - val_loss: 3.0924 - val_accuracy: 0.4669\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1645 - accuracy: 0.9421 - val_loss: 3.3650 - val_accuracy: 0.4655\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.1544 - accuracy: 0.9461 - val_loss: 3.2653 - val_accuracy: 0.4780\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.1437 - accuracy: 0.9498 - val_loss: 3.0673 - val_accuracy: 0.4710\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.1446 - accuracy: 0.9499 - val_loss: 3.3144 - val_accuracy: 0.4840curacy: 0.\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.1476 - accuracy: 0.9485 - val_loss: 3.7098 - val_accuracy: 0.4674\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1513 - accuracy: 0.9476 - val_loss: 3.1198 - val_accuracy: 0.4923\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.1311 - accuracy: 0.9551 - val_loss: 3.0029 - val_accuracy: 0.4872\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.1328 - accuracy: 0.9540 - val_loss: 3.6708 - val_accuracy: 0.4623\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.1285 - accuracy: 0.9551 - val_loss: 3.0316 - val_accuracy: 0.4912\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1300 - accuracy: 0.9548 - val_loss: 3.7878 - val_accuracy: 0.4489\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1316 - accuracy: 0.9542 - val_loss: 3.6508 - val_accuracy: 0.4658\n",
      "Numbers of exp: 2, use_preact: True, batch_size: 256\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 9s 45ms/step - loss: 1.7263 - accuracy: 0.4017 - val_loss: 2.0335 - val_accuracy: 0.2924\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.4603 - accuracy: 0.4839 - val_loss: 2.0405 - val_accuracy: 0.3050\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.3246 - accuracy: 0.5303 - val_loss: 1.8691 - val_accuracy: 0.3365\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.2300 - accuracy: 0.5633 - val_loss: 1.8061 - val_accuracy: 0.3698\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 1.1414 - accuracy: 0.5942 - val_loss: 1.6844 - val_accuracy: 0.3976\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.0649 - accuracy: 0.6221 - val_loss: 1.7522 - val_accuracy: 0.3720\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.9904 - accuracy: 0.6486 - val_loss: 1.8926 - val_accuracy: 0.3843\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.9169 - accuracy: 0.6735 - val_loss: 1.8014 - val_accuracy: 0.4024\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.8562 - accuracy: 0.6967 - val_loss: 1.8849 - val_accuracy: 0.3714\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.7838 - accuracy: 0.7228 - val_loss: 1.7862 - val_accuracy: 0.4124\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.7240 - accuracy: 0.7438 - val_loss: 1.9686 - val_accuracy: 0.3809\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.6705 - accuracy: 0.7633 - val_loss: 2.4547 - val_accuracy: 0.3594\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.6092 - accuracy: 0.7847 - val_loss: 1.9873 - val_accuracy: 0.4264\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.5507 - accuracy: 0.8076 - val_loss: 2.1366 - val_accuracy: 0.4016\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.5039 - accuracy: 0.8245 - val_loss: 2.0359 - val_accuracy: 0.4185\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.4605 - accuracy: 0.8381 - val_loss: 2.0236 - val_accuracy: 0.4442\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 0.4191 - accuracy: 0.8557 - val_loss: 2.2754 - val_accuracy: 0.3900\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.3746 - accuracy: 0.8695 - val_loss: 2.2145 - val_accuracy: 0.4450\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3439 - accuracy: 0.8804 - val_loss: 2.8132 - val_accuracy: 0.4093\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.3163 - accuracy: 0.8914 - val_loss: 2.5103 - val_accuracy: 0.4474\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2889 - accuracy: 0.9000 - val_loss: 2.5504 - val_accuracy: 0.4198\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2684 - accuracy: 0.9068 - val_loss: 2.4274 - val_accuracy: 0.4329\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2579 - accuracy: 0.9100 - val_loss: 2.6408 - val_accuracy: 0.4481\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2370 - accuracy: 0.9192 - val_loss: 3.0921 - val_accuracy: 0.4120\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.2223 - accuracy: 0.9239 - val_loss: 2.5368 - val_accuracy: 0.4323\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1996 - accuracy: 0.9307 - val_loss: 2.7842 - val_accuracy: 0.4379\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1975 - accuracy: 0.9317 - val_loss: 2.7195 - val_accuracy: 0.4398\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.2014 - accuracy: 0.9312 - val_loss: 2.9511 - val_accuracy: 0.4535\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1646 - accuracy: 0.9435 - val_loss: 3.3141 - val_accuracy: 0.4426\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1541 - accuracy: 0.9472 - val_loss: 2.8959 - val_accuracy: 0.4590\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1457 - accuracy: 0.9509 - val_loss: 2.9929 - val_accuracy: 0.4589\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1526 - accuracy: 0.9473 - val_loss: 3.1543 - val_accuracy: 0.4699\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1539 - accuracy: 0.9470 - val_loss: 3.0425 - val_accuracy: 0.4497\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1545 - accuracy: 0.9459 - val_loss: 3.2348 - val_accuracy: 0.4424\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1465 - accuracy: 0.9486 - val_loss: 3.3710 - val_accuracy: 0.4521\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1255 - accuracy: 0.9578 - val_loss: 3.2508 - val_accuracy: 0.4499\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1167 - accuracy: 0.9599 - val_loss: 3.0997 - val_accuracy: 0.4435\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1245 - accuracy: 0.9572 - val_loss: 3.2781 - val_accuracy: 0.4522\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1217 - accuracy: 0.9585 - val_loss: 3.1834 - val_accuracy: 0.4676\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1122 - accuracy: 0.9614 - val_loss: 3.7962 - val_accuracy: 0.4399\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1181 - accuracy: 0.9592 - val_loss: 3.5666 - val_accuracy: 0.4471\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1257 - accuracy: 0.9568 - val_loss: 3.4064 - val_accuracy: 0.4749\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1160 - accuracy: 0.9608 - val_loss: 3.2863 - val_accuracy: 0.4659\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1076 - accuracy: 0.9631 - val_loss: 3.3138 - val_accuracy: 0.4749\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1177 - accuracy: 0.9597 - val_loss: 3.1978 - val_accuracy: 0.4749\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.0888 - accuracy: 0.9689 - val_loss: 3.8290 - val_accuracy: 0.4616\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.0807 - accuracy: 0.9741 - val_loss: 3.6780 - val_accuracy: 0.4723\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.0908 - accuracy: 0.9699 - val_loss: 3.5153 - val_accuracy: 0.4587\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1059 - accuracy: 0.9634 - val_loss: 3.6088 - val_accuracy: 0.4632\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 4s 20ms/step - loss: 0.1039 - accuracy: 0.9645 - val_loss: 3.3727 - val_accuracy: 0.4756\n",
      "Numbers of exp: 3, use_preact: False, batch_size: 32\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.7654 - accuracy: 0.3736 - val_loss: 1.7107 - val_accuracy: 0.4001\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.5409 - accuracy: 0.4509 - val_loss: 1.6773 - val_accuracy: 0.4175\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.4420 - accuracy: 0.4879 - val_loss: 1.5102 - val_accuracy: 0.4646\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.3605 - accuracy: 0.5137 - val_loss: 1.5476 - val_accuracy: 0.4583\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.2934 - accuracy: 0.5401 - val_loss: 1.6905 - val_accuracy: 0.4307\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.2297 - accuracy: 0.5623 - val_loss: 1.5146 - val_accuracy: 0.4692\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1878 - accuracy: 0.5780 - val_loss: 1.4236 - val_accuracy: 0.5068\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 1.1308 - accuracy: 0.5972 - val_loss: 1.5787 - val_accuracy: 0.4745\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0817 - accuracy: 0.6137 - val_loss: 1.6995 - val_accuracy: 0.4293\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0348 - accuracy: 0.6301 - val_loss: 1.3595 - val_accuracy: 0.5265\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9934 - accuracy: 0.6450 - val_loss: 1.4783 - val_accuracy: 0.5095\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9487 - accuracy: 0.6600 - val_loss: 1.5139 - val_accuracy: 0.5052\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9095 - accuracy: 0.6744 - val_loss: 1.5708 - val_accuracy: 0.4831\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8699 - accuracy: 0.6885 - val_loss: 1.7357 - val_accuracy: 0.4591\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8382 - accuracy: 0.6999 - val_loss: 1.6499 - val_accuracy: 0.5102\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7896 - accuracy: 0.7168 - val_loss: 1.7641 - val_accuracy: 0.4872\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.7674 - accuracy: 0.7255 - val_loss: 1.9517 - val_accuracy: 0.4786\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7339 - accuracy: 0.7360 - val_loss: 1.5536 - val_accuracy: 0.5253\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7057 - accuracy: 0.7474 - val_loss: 1.6187 - val_accuracy: 0.5068\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6777 - accuracy: 0.7573 - val_loss: 1.7041 - val_accuracy: 0.5031\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6524 - accuracy: 0.7659 - val_loss: 1.8511 - val_accuracy: 0.4787\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6250 - accuracy: 0.7753 - val_loss: 2.0656 - val_accuracy: 0.4783\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.6028 - accuracy: 0.7851 - val_loss: 1.7630 - val_accuracy: 0.5148\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5784 - accuracy: 0.7917 - val_loss: 1.8295 - val_accuracy: 0.5091\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.5552 - accuracy: 0.8015 - val_loss: 1.9504 - val_accuracy: 0.5024\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.5354 - accuracy: 0.8081 - val_loss: 1.9882 - val_accuracy: 0.4960\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5201 - accuracy: 0.8132 - val_loss: 1.9416 - val_accuracy: 0.5196\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.5002 - accuracy: 0.8219 - val_loss: 1.8898 - val_accuracy: 0.5086\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.4882 - accuracy: 0.8264 - val_loss: 2.3555 - val_accuracy: 0.4599\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.4663 - accuracy: 0.8360 - val_loss: 2.2447 - val_accuracy: 0.4676\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4624 - accuracy: 0.8354 - val_loss: 2.1245 - val_accuracy: 0.4953\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.4423 - accuracy: 0.8441 - val_loss: 2.2803 - val_accuracy: 0.4977\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4227 - accuracy: 0.8482 - val_loss: 2.0831 - val_accuracy: 0.5232\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4199 - accuracy: 0.8494 - val_loss: 2.3805 - val_accuracy: 0.4795\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4031 - accuracy: 0.8556 - val_loss: 2.3050 - val_accuracy: 0.5003\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.3960 - accuracy: 0.8590 - val_loss: 2.6194 - val_accuracy: 0.4724\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.3905 - accuracy: 0.8602 - val_loss: 2.2887 - val_accuracy: 0.5101\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3790 - accuracy: 0.8636 - val_loss: 2.3882 - val_accuracy: 0.4857\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3743 - accuracy: 0.8670 - val_loss: 2.1668 - val_accuracy: 0.5114\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3542 - accuracy: 0.8725 - val_loss: 2.3836 - val_accuracy: 0.5049\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3503 - accuracy: 0.8759 - val_loss: 2.1014 - val_accuracy: 0.5143\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.3352 - accuracy: 0.8793 - val_loss: 2.7098 - val_accuracy: 0.4977\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3255 - accuracy: 0.8838 - val_loss: 2.3111 - val_accuracy: 0.5043\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.3331 - accuracy: 0.8808 - val_loss: 2.4572 - val_accuracy: 0.4873\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.3182 - accuracy: 0.8874 - val_loss: 2.1674 - val_accuracy: 0.5138\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.3177 - accuracy: 0.8867 - val_loss: 2.2918 - val_accuracy: 0.5161\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.3097 - accuracy: 0.8897 - val_loss: 2.3289 - val_accuracy: 0.5104\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.2964 - accuracy: 0.8952 - val_loss: 2.3781 - val_accuracy: 0.5070\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.2923 - accuracy: 0.8949 - val_loss: 2.3721 - val_accuracy: 0.5077\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.2875 - accuracy: 0.8974 - val_loss: 2.8006 - val_accuracy: 0.4891\n",
      "Numbers of exp: 4, use_preact: False, batch_size: 128\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.7334 - accuracy: 0.3951 - val_loss: 2.2740 - val_accuracy: 0.2554\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 1.4657 - accuracy: 0.4788 - val_loss: 1.8156 - val_accuracy: 0.3669\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3340 - accuracy: 0.5264 - val_loss: 1.7758 - val_accuracy: 0.3737\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2391 - accuracy: 0.5590 - val_loss: 1.6268 - val_accuracy: 0.4298\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 1.1578 - accuracy: 0.5873 - val_loss: 1.7372 - val_accuracy: 0.3935\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0933 - accuracy: 0.6103 - val_loss: 1.5880 - val_accuracy: 0.4461\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 1.0205 - accuracy: 0.6372 - val_loss: 1.7755 - val_accuracy: 0.3852\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.9620 - accuracy: 0.6598 - val_loss: 1.6731 - val_accuracy: 0.4079\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.8973 - accuracy: 0.6825 - val_loss: 1.6970 - val_accuracy: 0.4574\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.8359 - accuracy: 0.7009 - val_loss: 1.7307 - val_accuracy: 0.4098\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 0.7762 - accuracy: 0.7222 - val_loss: 1.7198 - val_accuracy: 0.4259\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.7221 - accuracy: 0.7412 - val_loss: 2.1447 - val_accuracy: 0.4031\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.6647 - accuracy: 0.7647 - val_loss: 1.7385 - val_accuracy: 0.4491\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.6205 - accuracy: 0.7795 - val_loss: 1.8750 - val_accuracy: 0.4452\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.5689 - accuracy: 0.7973 - val_loss: 2.1443 - val_accuracy: 0.4261\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 0.5231 - accuracy: 0.8141 - val_loss: 1.8231 - val_accuracy: 0.4642\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.4894 - accuracy: 0.8262 - val_loss: 2.2858 - val_accuracy: 0.4260\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.4521 - accuracy: 0.8401 - val_loss: 2.2311 - val_accuracy: 0.4460\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.4131 - accuracy: 0.8562 - val_loss: 2.2711 - val_accuracy: 0.4186\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.3864 - accuracy: 0.8633 - val_loss: 2.5858 - val_accuracy: 0.4408\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.3632 - accuracy: 0.8733 - val_loss: 2.4951 - val_accuracy: 0.4386\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3429 - accuracy: 0.8772 - val_loss: 2.5668 - val_accuracy: 0.4232\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.3234 - accuracy: 0.8848 - val_loss: 3.2483 - val_accuracy: 0.4253\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.2982 - accuracy: 0.8928 - val_loss: 2.8911 - val_accuracy: 0.4181\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.2705 - accuracy: 0.9061 - val_loss: 2.5532 - val_accuracy: 0.4725\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.2656 - accuracy: 0.9077 - val_loss: 2.3947 - val_accuracy: 0.4581\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.2587 - accuracy: 0.9089 - val_loss: 2.6975 - val_accuracy: 0.4728\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 0.2390 - accuracy: 0.9153 - val_loss: 2.4961 - val_accuracy: 0.4475\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.2226 - accuracy: 0.9216 - val_loss: 3.1171 - val_accuracy: 0.4329\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.2228 - accuracy: 0.9226 - val_loss: 3.0967 - val_accuracy: 0.4466\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 0.2128 - accuracy: 0.9249 - val_loss: 2.9004 - val_accuracy: 0.4809\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.2054 - accuracy: 0.9271 - val_loss: 3.2384 - val_accuracy: 0.4663\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1936 - accuracy: 0.9332 - val_loss: 2.9973 - val_accuracy: 0.4700\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1901 - accuracy: 0.9336 - val_loss: 3.0876 - val_accuracy: 0.4511\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.1911 - accuracy: 0.9332 - val_loss: 2.8183 - val_accuracy: 0.4649\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.1653 - accuracy: 0.9421 - val_loss: 3.1785 - val_accuracy: 0.4488\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.1754 - accuracy: 0.9388 - val_loss: 3.6319 - val_accuracy: 0.4549\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.1659 - accuracy: 0.9425 - val_loss: 3.7445 - val_accuracy: 0.4525\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.1606 - accuracy: 0.9433 - val_loss: 3.4927 - val_accuracy: 0.4658\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.1557 - accuracy: 0.9450 - val_loss: 3.2493 - val_accuracy: 0.4550\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1520 - accuracy: 0.9462 - val_loss: 3.1781 - val_accuracy: 0.4811\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.1436 - accuracy: 0.9508 - val_loss: 3.5091 - val_accuracy: 0.4439\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.1461 - accuracy: 0.9487 - val_loss: 2.9051 - val_accuracy: 0.4776\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.1465 - accuracy: 0.9487 - val_loss: 2.8921 - val_accuracy: 0.4876\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.1337 - accuracy: 0.9539 - val_loss: 3.3373 - val_accuracy: 0.4535\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.1355 - accuracy: 0.9528 - val_loss: 3.7204 - val_accuracy: 0.4636\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.1315 - accuracy: 0.9540 - val_loss: 4.2611 - val_accuracy: 0.4438\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.1232 - accuracy: 0.9587 - val_loss: 3.5764 - val_accuracy: 0.4711\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.1310 - accuracy: 0.9542 - val_loss: 3.3686 - val_accuracy: 0.4734\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 3.4202 - val_accuracy: 0.4890\n",
      "Numbers of exp: 5, use_preact: False, batch_size: 256\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.7462 - accuracy: 0.3930 - val_loss: 2.2137 - val_accuracy: 0.2476\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4700 - accuracy: 0.4831 - val_loss: 1.8991 - val_accuracy: 0.3269\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.3337 - accuracy: 0.5244 - val_loss: 1.9824 - val_accuracy: 0.3329\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.2370 - accuracy: 0.5596 - val_loss: 1.7906 - val_accuracy: 0.3687\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.1478 - accuracy: 0.5921 - val_loss: 1.7688 - val_accuracy: 0.3742\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.0734 - accuracy: 0.6189 - val_loss: 1.9430 - val_accuracy: 0.3497\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.9940 - accuracy: 0.6494 - val_loss: 1.7746 - val_accuracy: 0.3774\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.9248 - accuracy: 0.6696 - val_loss: 1.8300 - val_accuracy: 0.4163\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.8588 - accuracy: 0.6948 - val_loss: 1.9307 - val_accuracy: 0.3783\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 4s 21ms/step - loss: 0.7923 - accuracy: 0.7197 - val_loss: 2.4997 - val_accuracy: 0.3338\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.7326 - accuracy: 0.7404 - val_loss: 1.7390 - val_accuracy: 0.4310\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.6690 - accuracy: 0.7636 - val_loss: 1.9330 - val_accuracy: 0.4053\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.6147 - accuracy: 0.7834 - val_loss: 1.9041 - val_accuracy: 0.3900\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.5581 - accuracy: 0.8033 - val_loss: 1.8839 - val_accuracy: 0.4293\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 0.5047 - accuracy: 0.8243 - val_loss: 2.1700 - val_accuracy: 0.4042\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.4714 - accuracy: 0.8345 - val_loss: 2.0955 - val_accuracy: 0.4295\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.4174 - accuracy: 0.8539 - val_loss: 2.2464 - val_accuracy: 0.4272\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.3814 - accuracy: 0.8664 - val_loss: 2.1900 - val_accuracy: 0.4326\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.3465 - accuracy: 0.8796 - val_loss: 2.2921 - val_accuracy: 0.4400\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.3204 - accuracy: 0.8897 - val_loss: 2.4600 - val_accuracy: 0.4171\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.2927 - accuracy: 0.8975 - val_loss: 2.5630 - val_accuracy: 0.4126\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.2780 - accuracy: 0.9038 - val_loss: 2.5416 - val_accuracy: 0.4563\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 0.2550 - accuracy: 0.9112 - val_loss: 2.8952 - val_accuracy: 0.4060\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.2376 - accuracy: 0.9168 - val_loss: 2.5441 - val_accuracy: 0.4593\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.2184 - accuracy: 0.9240 - val_loss: 2.6847 - val_accuracy: 0.4365\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.2150 - accuracy: 0.9262 - val_loss: 2.7460 - val_accuracy: 0.4448\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9370 - val_loss: 3.0957 - val_accuracy: 0.4492\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1761 - accuracy: 0.9386 - val_loss: 3.1439 - val_accuracy: 0.4360\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1795 - accuracy: 0.9371 - val_loss: 3.1370 - val_accuracy: 0.4275\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1609 - accuracy: 0.9448 - val_loss: 3.2271 - val_accuracy: 0.4528\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1524 - accuracy: 0.9472 - val_loss: 3.3903 - val_accuracy: 0.4457\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1610 - accuracy: 0.9440 - val_loss: 3.1085 - val_accuracy: 0.4803\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1585 - accuracy: 0.9445 - val_loss: 2.9311 - val_accuracy: 0.4678\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1431 - accuracy: 0.9498 - val_loss: 3.0150 - val_accuracy: 0.4685\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1424 - accuracy: 0.9502 - val_loss: 3.2026 - val_accuracy: 0.4685\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1422 - accuracy: 0.9507 - val_loss: 3.5969 - val_accuracy: 0.4144\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1396 - accuracy: 0.9532 - val_loss: 3.2594 - val_accuracy: 0.4692\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1243 - accuracy: 0.9578 - val_loss: 3.5160 - val_accuracy: 0.4428\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1166 - accuracy: 0.9610 - val_loss: 3.3716 - val_accuracy: 0.4708\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 0.1085 - accuracy: 0.9644 - val_loss: 3.0958 - val_accuracy: 0.4858\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1255 - accuracy: 0.9561 - val_loss: 3.5452 - val_accuracy: 0.4642\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1443 - accuracy: 0.9491 - val_loss: 3.4358 - val_accuracy: 0.4527\n",
      "Epoch 43/50\n",
      "139/196 [====================>.........] - ETA: 1s - loss: 0.1095 - accuracy: 0.9618"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i, (before, bz) in enumerate(itertools.product(BEFORE_ACTIVATE, BATCH_SIZE)):\n",
    "    print(\"Numbers of exp: %i, use_preact: %s, batch_size: %i\" % (i, before, bz))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=bz, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "\n",
    "    # Collect results\n",
    "    exp_name_tag = (\"exp-%s\" % (i))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"accuracy\"],\n",
    "                             'valid-acc': model.history.history[\"val_accuracy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "NUM_COLORS = 20\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
